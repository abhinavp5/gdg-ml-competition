{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intial Testing of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_top_1000.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mat[\u001b[38;5;241m966\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReleased_Year\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1995\u001b[39m \u001b[38;5;66;03m#fixing the wrong value for apollo 13 \u001b[39;00m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoster_Link\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb_top_1000.csv')\n",
    "df.at[966,\"Released_Year\"] = 1995 #fixing the wrong value for apollo 13 \n",
    "df.drop(columns = [\"Poster_Link\"], inplace= True)\n",
    "df.dropna(inplace = True) #dropping null valued columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Converting to Numeric Values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGross\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGross\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReleased_Year\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReleased_Year\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:6293\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6287\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6288\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6289\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6290\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6291\u001b[0m ):\n\u001b[1;32m   6292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/strings/accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/strings/accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "#Converting to Numeric Values\n",
    "df[\"Gross\"] = df[\"Gross\"].str.replace(\",\", \"\").astype(\"float\")\n",
    "df[\"Released_Year\"] = df[\"Released_Year\"].astype(\"int\")\n",
    "df[\"Runtime\"] = df[\"Runtime\"].str.replace(\" min\", \"\").astype(\"int\")\n",
    "df[\"IMDB_Rating\"] = df[\"IMDB_Rating\"].astype(float)\n",
    "df[\"Meta_score\"] = df[\"Meta_score\"].astype(float)\n",
    "df[\"No_of_Votes\"] = df[\"No_of_Votes\"].astype(float)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'smooth_target_encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDB_Rating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msmooth_target_encode\u001b[49m(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDB_Rating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGross\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta_score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m smooth_target_encode(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGross\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo_of_Votes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m smooth_target_encode(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo_of_Votes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGross\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'smooth_target_encode' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"IMDB_Rating\"] = smooth_target_encode(df, \"IMDB_Rating\", \"Gross\")\n",
    "df[\"Meta_score\"] = smooth_target_encode(df, \"Meta_score\", \"Gross\")\n",
    "df[\"No_of_Votes\"] = smooth_target_encode(df, \"No_of_Votes\", \"Gross\")\n",
    "df[\"Certificate\"] = smooth_target_encode(df, \"Certificate\", \"Gross\")\n",
    "df[\"Genre\"] = smooth_target_encode(df, \"Genre\", \"Gross\")\n",
    "df[\"Director\"] = smooth_target_encode(df, \"Director\", \"Gross\")\n",
    "df[\"Star1\"] = smooth_target_encode(df, \"Star1\", \"Gross\")\n",
    "df[\"Star2\"] = smooth_target_encode(df, \"Star2\", \"Gross\")\n",
    "df[\"Star3\"] = smooth_target_encode(df, \"Star3\", \"Gross\")\n",
    "df[\"Star4\"] = smooth_target_encode(df, \"Star4\", \"Gross\")\n",
    "df[\"Series_Title\"] = smooth_target_encode(df, \"Series_Title\", \"Gross\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying One Hot Encoding\n",
    "Thoughts - Too many features \\\n",
    "Results - Not Tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_encoded_shape(714, 2953)\n",
      "df_shape(714, 15)\n"
     ]
    }
   ],
   "source": [
    "#One Hot encoding for Certificate, Genre, Director, Star1, Star2, Star3, Star 4\n",
    "df_encoded = pd.get_dummies(df, columns = [\"Certificate\", \"Genre\", \"Director\", \"Star1\", \"Star2\", \"Star3\", \"Star4\"])\n",
    "print(f\"df_encoded_shape{df_encoded.shape}\")\n",
    "print(f\"df_shape{df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functino to encode the target variable\n",
    "def smooth_target_encode(df, col, target, smoothing_param =.3):\n",
    "    mean_target = df[target].mean()\n",
    "    encoded =df.groupby(col)[target].agg([\"count\", \"mean\"])\n",
    "    counts = encoded[\"count\"]\n",
    "    means = encoded[\"mean\"]\n",
    "    smooth_encodings = (means*counts + mean_target*smoothing_param)/(counts+smoothing_param)\n",
    "    return df[col].map(smooth_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"IMDB_Rating\"] = smooth_target_encode(df, \"IMDB_Rating\", \"Gross\")\n",
    "df[\"Meta_score\"] = smooth_target_encode(df, \"Meta_score\", \"Gross\")\n",
    "df[\"No_of_Votes\"] = smooth_target_encode(df, \"No_of_Votes\", \"Gross\")\n",
    "df[\"Certificate\"] = smooth_target_encode(df, \"Certificate\", \"Gross\")\n",
    "df[\"Genre\"] = smooth_target_encode(df, \"Genre\", \"Gross\")\n",
    "df[\"Director\"] = smooth_target_encode(df, \"Director\", \"Gross\")\n",
    "df[\"Star1\"] = smooth_target_encode(df, \"Star1\", \"Gross\")\n",
    "df[\"Star2\"] = smooth_target_encode(df, \"Star2\", \"Gross\")\n",
    "df[\"Star3\"] = smooth_target_encode(df, \"Star3\", \"Gross\")\n",
    "df[\"Star4\"] = smooth_target_encode(df, \"Star4\", \"Gross\")\n",
    "df[\"Series_Title\"] = smooth_target_encode(df, \"Series_Title\", \"Gross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_Title</th>\n",
       "      <th>Released_Year</th>\n",
       "      <th>Certificate</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Genre</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "      <th>Overview</th>\n",
       "      <th>Meta_score</th>\n",
       "      <th>Director</th>\n",
       "      <th>Star1</th>\n",
       "      <th>Star2</th>\n",
       "      <th>Star3</th>\n",
       "      <th>Star4</th>\n",
       "      <th>No_of_Votes</th>\n",
       "      <th>Gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>1994</td>\n",
       "      <td>6.605757e+07</td>\n",
       "      <td>142</td>\n",
       "      <td>3.478698e+07</td>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "      <td>1.049399e+08</td>\n",
       "      <td>8.204214e+07</td>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>3.991965e+07</td>\n",
       "      <td>28341469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.219388e+08</td>\n",
       "      <td>1972</td>\n",
       "      <td>6.605757e+07</td>\n",
       "      <td>175</td>\n",
       "      <td>3.328097e+07</td>\n",
       "      <td>1.219388e+08</td>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "      <td>2.578054e+07</td>\n",
       "      <td>6.988265e+07</td>\n",
       "      <td>7.309586e+07</td>\n",
       "      <td>5.893506e+07</td>\n",
       "      <td>1.219388e+08</td>\n",
       "      <td>9.383499e+07</td>\n",
       "      <td>1.219388e+08</td>\n",
       "      <td>134966411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.295481e+08</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.499447e+08</td>\n",
       "      <td>152</td>\n",
       "      <td>7.275734e+07</td>\n",
       "      <td>1.879008e+08</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>8.741143e+07</td>\n",
       "      <td>2.362660e+08</td>\n",
       "      <td>1.656802e+08</td>\n",
       "      <td>2.788940e+08</td>\n",
       "      <td>4.295481e+08</td>\n",
       "      <td>1.803062e+08</td>\n",
       "      <td>4.295481e+08</td>\n",
       "      <td>534858444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.219544e+07</td>\n",
       "      <td>1974</td>\n",
       "      <td>6.605757e+07</td>\n",
       "      <td>202</td>\n",
       "      <td>3.328097e+07</td>\n",
       "      <td>1.879008e+08</td>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "      <td>7.654053e+07</td>\n",
       "      <td>6.988265e+07</td>\n",
       "      <td>4.794513e+07</td>\n",
       "      <td>1.465885e+08</td>\n",
       "      <td>7.144591e+07</td>\n",
       "      <td>9.383499e+07</td>\n",
       "      <td>6.219544e+07</td>\n",
       "      <td>57300000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.110124e+07</td>\n",
       "      <td>1957</td>\n",
       "      <td>9.459847e+07</td>\n",
       "      <td>96</td>\n",
       "      <td>3.328097e+07</td>\n",
       "      <td>1.879008e+08</td>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "      <td>6.266548e+07</td>\n",
       "      <td>3.760792e+07</td>\n",
       "      <td>1.008806e+07</td>\n",
       "      <td>1.110124e+07</td>\n",
       "      <td>1.403221e+07</td>\n",
       "      <td>1.110124e+07</td>\n",
       "      <td>1.110124e+07</td>\n",
       "      <td>4360000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Series_Title  Released_Year   Certificate  Runtime         Genre  \\\n",
       "0  3.991965e+07           1994  6.605757e+07      142  3.478698e+07   \n",
       "1  1.219388e+08           1972  6.605757e+07      175  3.328097e+07   \n",
       "2  4.295481e+08           2008  1.499447e+08      152  7.275734e+07   \n",
       "3  6.219544e+07           1974  6.605757e+07      202  3.328097e+07   \n",
       "4  1.110124e+07           1957  9.459847e+07       96  3.328097e+07   \n",
       "\n",
       "    IMDB_Rating                                           Overview  \\\n",
       "0  3.991965e+07  Two imprisoned men bond over a number of years...   \n",
       "1  1.219388e+08  An organized crime dynasty's aging patriarch t...   \n",
       "2  1.879008e+08  When the menace known as the Joker wreaks havo...   \n",
       "3  1.879008e+08  The early life and career of Vito Corleone in ...   \n",
       "4  1.879008e+08  A jury holdout attempts to prevent a miscarria...   \n",
       "\n",
       "     Meta_score      Director         Star1         Star2         Star3  \\\n",
       "0  1.049399e+08  8.204214e+07  3.991965e+07  3.991965e+07  3.991965e+07   \n",
       "1  2.578054e+07  6.988265e+07  7.309586e+07  5.893506e+07  1.219388e+08   \n",
       "2  8.741143e+07  2.362660e+08  1.656802e+08  2.788940e+08  4.295481e+08   \n",
       "3  7.654053e+07  6.988265e+07  4.794513e+07  1.465885e+08  7.144591e+07   \n",
       "4  6.266548e+07  3.760792e+07  1.008806e+07  1.110124e+07  1.403221e+07   \n",
       "\n",
       "          Star4   No_of_Votes        Gross  \n",
       "0  3.991965e+07  3.991965e+07   28341469.0  \n",
       "1  9.383499e+07  1.219388e+08  134966411.0  \n",
       "2  1.803062e+08  4.295481e+08  534858444.0  \n",
       "3  9.383499e+07  6.219544e+07   57300000.0  \n",
       "4  1.110124e+07  1.110124e+07    4360000.0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bert embeddings for overview column, Unesecarry for RF or Xgbost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load a lightweight BERT model (fast & efficient)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Outputs 384D embeddings\n",
    "\n",
    "# Convert each overview into a 384-dimensional vector\n",
    "df[\"Overview\"] = df['Overview'].apply(lambda x: model.encode(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 15)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim=7, hidden1=128, hidden2=64, dropout_prob=0.2):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        \n",
    "        # Layer 1: Fully connected\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        # Batch Norm after first layer\n",
    "        self.bn1 = nn.BatchNorm1d(hidden1)\n",
    "        # Dropout\n",
    "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
    "    \n",
    "        # Layer 2: Fully connected\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        # Batch Norm after second layer\n",
    "        self.bn2 = nn.BatchNorm1d(hidden2)\n",
    "        # Dropout\n",
    "        self.dropout2 = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        # Output Layer\n",
    "        self.fc3 = nn.Linear(hidden2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First layer + activation + batchnorm + dropout\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Second layer + activation + batchnorm + dropout\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Output layer (no activation for regression)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppose you have data of shape (7383, 7)\n",
    "# We'll create a random example input for demonstration:\n",
    "# Typically, you'd load your own dataset here.\n",
    "dummy_input = torch.randn(7383, 7)\n",
    "dummy_targets = torch.randn(7383, 1)  # e.g., regression targets\n",
    "\n",
    "model = RegressionModel(input_dim=7, hidden1=128, hidden2=64, dropout_prob=0.2)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# Use a small weight_decay for L2 regularization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Simple training loop (illustrative only)\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle the data for each epoch (optional in real code; recommended in practice)\n",
    "    permutation = torch.randperm(dummy_input.size()[0])\n",
    "    \n",
    "    # Mini-batch training\n",
    "    for i in range(0, dummy_input.size(0), batch_size):\n",
    "        indices = permutation[i : i + batch_size]\n",
    "        batch_x, batch_y = dummy_input[indices], dummy_targets[indices]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass & update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
